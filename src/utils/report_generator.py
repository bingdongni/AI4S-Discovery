#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æŠ¥å‘Šç”Ÿæˆå™¨
æ”¯æŒå¤šç§æ ¼å¼ï¼šPDFã€DOCXã€HTMLã€Markdown
"""

import os
from pathlib import Path
from datetime import datetime
from typing import Dict
from jinja2 import Template
from loguru import logger

from src.core.config import settings


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨"""
        self.template_dir = Path(settings.REPORT_TEMPLATE_PATH)
        self.output_dir = Path(settings.REPORT_OUTPUT_PATH)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        logger.info("æŠ¥å‘Šç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def generate(
        self,
        result: Dict,
        output_path: str,
        format: str = 'markdown',
        template: str = 'default',
    ):
        """
        ç”ŸæˆæŠ¥å‘Š
        
        Args:
            result: ç ”ç©¶ç»“æœ
            output_path: è¾“å‡ºè·¯å¾„
            format: æŠ¥å‘Šæ ¼å¼
            template: æ¨¡æ¿åç§°
        """
        logger.info(f"ç”Ÿæˆ{format}æŠ¥å‘Š: {output_path}")
        
        if format == 'markdown':
            self._generate_markdown(result, output_path)
        elif format == 'html':
            self._generate_html(result, output_path)
        elif format == 'pdf':
            # PDFç”Ÿæˆéœ€è¦å…ˆç”ŸæˆHTMLå†è½¬æ¢
            html_path = output_path.replace('.pdf', '.html')
            self._generate_html(result, html_path)
            logger.info(f"PDFç”Ÿæˆéœ€è¦é¢å¤–å·¥å…·ï¼Œå·²ç”ŸæˆHTMLç‰ˆæœ¬: {html_path}")
        elif format == 'docx':
            logger.warning("DOCXæ ¼å¼æš‚æœªå®ç°ï¼Œç”ŸæˆMarkdownä»£æ›¿")
            self._generate_markdown(result, output_path.replace('.docx', '.md'))
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")
    
    def _generate_markdown(self, result: Dict, output_path: str):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        content = self._build_markdown_content(result)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.success(f"MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
    
    def _generate_html(self, result: Dict, output_path: str):
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        markdown_content = self._build_markdown_content(result)
        
        # ç®€å•çš„HTMLæ¨¡æ¿
        html_template = """
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>AI4S-Discovery ç ”ç©¶æŠ¥å‘Š</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        h1 { color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }
        h2 { color: #34495e; border-bottom: 2px solid #95a5a6; padding-bottom: 8px; margin-top: 30px; }
        h3 { color: #7f8c8d; }
        table { border-collapse: collapse; width: 100%; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
        th { background-color: #3498db; color: white; }
        tr:nth-child(even) { background-color: #f2f2f2; }
        .stat-box { background: #ecf0f1; padding: 15px; border-radius: 5px; margin: 10px 0; }
        .keyword { display: inline-block; background: #3498db; color: white; padding: 5px 10px; margin: 5px; border-radius: 3px; }
    </style>
</head>
<body>
    <pre>{{ content }}</pre>
</body>
</html>
        """
        
        template = Template(html_template)
        html_content = template.render(content=markdown_content)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        logger.success(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
    
    def _build_markdown_content(self, result: Dict) -> str:
        """æ„å»ºMarkdownå†…å®¹"""
        lines = []
        
        # æ ‡é¢˜
        lines.append("# AI4S-Discovery ç ”ç©¶æŠ¥å‘Š")
        lines.append(f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        lines.append("---\n")
        
        # 1. æ–‡çŒ®ç»Ÿè®¡
        literature = result.get('literature', {})
        lines.append("## ğŸ“š æ–‡çŒ®ç»Ÿè®¡\n")
        lines.append(f"- **æ€»è®¡**: {literature.get('total_papers', 0)} ç¯‡")
        lines.append(f"- **æ¥æºåˆ†å¸ƒ**:")
        for source, count in literature.get('sources', {}).items():
            lines.append(f"  - {source}: {count} ç¯‡")
        lines.append("")
        
        # 2. åˆ†æç»“æœ
        analysis = result.get('analysis', {})
        if analysis:
            lines.append("## ğŸ“Š åˆ†æç»“æœ\n")
            
            stats = analysis.get('statistics', {})
            lines.append("### è´¨é‡åˆ†æ")
            lines.append(f"- åˆ†ææ€»æ•°: {analysis.get('total_analyzed', 0)} ç¯‡")
            lines.append(f"- é«˜è´¨é‡æ–‡çŒ®: {analysis.get('high_quality_count', 0)} ç¯‡")
            lines.append(f"- è´¨é‡é˜ˆå€¼: {analysis.get('quality_threshold', 0)}")
            lines.append(f"- å¹³å‡å¼•ç”¨æ•°: {stats.get('avg_citations', 0):.1f}")
            lines.append("")
            
            # å…³é”®è¯
            keywords = analysis.get('keywords', [])[:20]
            if keywords:
                lines.append("### ğŸ”‘ å…³é”®è¯ï¼ˆTop 20ï¼‰\n")
                lines.append("| æ’å | å…³é”®è¯ | TF-IDF | é¢‘æ¬¡ |")
                lines.append("|------|--------|--------|------|")
                for idx, kw in enumerate(keywords, 1):
                    lines.append(f"| {idx} | {kw.get('term', '')} | {kw.get('tfidf_score', 0):.4f} | {kw.get('frequency', 0)} |")
                lines.append("")
            
            # è¶‹åŠ¿åˆ†æ
            trends = analysis.get('trends', {})
            if trends:
                lines.append("### ğŸ“ˆ ç ”ç©¶è¶‹åŠ¿\n")
                
                # å¹´åº¦åˆ†å¸ƒ
                yearly = trends.get('yearly_distribution', {})
                if yearly:
                    lines.append("#### å¹´åº¦åˆ†å¸ƒ")
                    for year, count in sorted(yearly.items()):
                        lines.append(f"- {year}: {count} ç¯‡")
                    lines.append("")
                
                # é«˜äº§ä½œè€…
                authors = trends.get('author_distribution', {})
                if authors:
                    lines.append("#### é«˜äº§ä½œè€…ï¼ˆTop 10ï¼‰")
                    for author, count in list(authors.items())[:10]:
                        lines.append(f"- {author}: {count} ç¯‡")
                    lines.append("")
            
            # å…³é”®å‘ç°
            findings = analysis.get('key_findings', [])
            if findings:
                lines.append("### ğŸ’¡ å…³é”®å‘ç°\n")
                for idx, finding in enumerate(findings, 1):
                    lines.append(f"#### {idx}. {finding.get('title', '')}")
                    lines.append(f"**ä½œè€…**: {', '.join(finding.get('authors', [])[:3])}")
                    lines.append(f"**å¹´ä»½**: {finding.get('year', 'N/A')} | "
                               f"**è´¨é‡åˆ†**: {finding.get('quality_score', 0):.1f} | "
                               f"**å¼•ç”¨**: {finding.get('citations', 0)}")
                    lines.append(f"\n**æ‘˜è¦**: {finding.get('abstract', '')}\n")
        
        # 3. çŸ¥è¯†å›¾è°±åˆ†æ
        graph = result.get('knowledge_graph', {})
        if graph:
            lines.append("## ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±åˆ†æ\n")
            
            # åŸºæœ¬ç»Ÿè®¡
            lines.append("### å›¾è°±ç»Ÿè®¡")
            lines.append(f"- **èŠ‚ç‚¹æ•°**: {graph.get('node_count', 0)}")
            lines.append(f"- **è¾¹æ•°**: {graph.get('edge_count', 0)}")
            lines.append(f"- **å¹³å‡åº¦**: {graph.get('avg_degree', 0):.2f}")
            lines.append(f"- **å›¾å¯†åº¦**: {graph.get('density', 0):.4f}")
            lines.append("")
            
            # ç¤¾åŒºç»“æ„
            communities = graph.get('communities', [])
            if communities:
                lines.append("### ç ”ç©¶ç¤¾åŒº")
                lines.append(f"å‘ç° {len(communities)} ä¸ªç ”ç©¶ç¤¾åŒºï¼š\n")
                for idx, comm in enumerate(communities[:5], 1):
                    lines.append(f"#### ç¤¾åŒº {idx}")
                    lines.append(f"- è§„æ¨¡: {comm.get('size', 0)} ä¸ªèŠ‚ç‚¹")
                    lines.append(f"- æ ¸å¿ƒä¸»é¢˜: {', '.join(comm.get('topics', [])[:5])}")
                    lines.append(f"- ä»£è¡¨æ–‡çŒ®: {comm.get('representative_papers', ['N/A'])[0]}")
                    lines.append("")
            
            # å…³é”®èŠ‚ç‚¹
            key_nodes = graph.get('key_nodes', [])
            if key_nodes:
                lines.append("### å…³é”®èŠ‚ç‚¹ï¼ˆTop 10ï¼‰\n")
                lines.append("| æ’å | æ–‡çŒ® | åº¦ä¸­å¿ƒæ€§ | ä»‹æ•°ä¸­å¿ƒæ€§ | PageRank |")
                lines.append("|------|------|----------|------------|----------|")
                for idx, node in enumerate(key_nodes[:10], 1):
                    lines.append(f"| {idx} | {node.get('title', '')[:50]}... | "
                               f"{node.get('degree_centrality', 0):.4f} | "
                               f"{node.get('betweenness_centrality', 0):.4f} | "
                               f"{node.get('pagerank', 0):.4f} |")
                lines.append("")
        
        # 4. TRLæŠ€æœ¯æˆç†Ÿåº¦è¯„ä¼°
        trl = result.get('trl_assessment', {})
        if trl:
            lines.append("## ğŸ“Š æŠ€æœ¯æˆç†Ÿåº¦è¯„ä¼°ï¼ˆTRLï¼‰\n")
            
            # æ€»ä½“è¯„ä¼°
            lines.append("### æ€»ä½“è¯„ä¼°")
            lines.append(f"- **TRLç­‰çº§**: {trl.get('trl_level', 'N/A')}")
            lines.append(f"- **ç½®ä¿¡åº¦**: {trl.get('confidence', 0):.2%}")
            lines.append(f"- **è¯„ä¼°æ–¹æ³•**: {trl.get('method', 'N/A')}")
            lines.append("")
            
            # TRLåˆ†å¸ƒ
            distribution = trl.get('distribution', {})
            if distribution:
                lines.append("### TRLç­‰çº§åˆ†å¸ƒ\n")
                lines.append("| TRLç­‰çº§ | æ–‡çŒ®æ•°é‡ | å æ¯” |")
                lines.append("|---------|----------|------|")
                for level in range(1, 10):
                    count = distribution.get(f'TRL{level}', 0)
                    if count > 0:
                        percentage = count / trl.get('total_papers', 1) * 100
                        lines.append(f"| TRL {level} | {count} | {percentage:.1f}% |")
                lines.append("")
            
            # æŠ€æœ¯å¯è¡Œæ€§
            feasibility = trl.get('feasibility', {})
            if feasibility:
                lines.append("### æŠ€æœ¯å¯è¡Œæ€§åˆ†æ")
                lines.append(f"- **æŠ€æœ¯æˆç†Ÿåº¦**: {feasibility.get('maturity', 'N/A')}")
                lines.append(f"- **å®æ–½éš¾åº¦**: {feasibility.get('difficulty', 'N/A')}")
                lines.append(f"- **èµ„æºéœ€æ±‚**: {feasibility.get('resource_requirement', 'N/A')}")
                lines.append(f"- **æ—¶é—´ä¼°è®¡**: {feasibility.get('time_estimate', 'N/A')}")
                lines.append("")
            
            # å…³é”®é‡Œç¨‹ç¢‘
            milestones = trl.get('milestones', [])
            if milestones:
                lines.append("### å…³é”®é‡Œç¨‹ç¢‘")
                for milestone in milestones:
                    lines.append(f"- **{milestone.get('stage', '')}**: {milestone.get('description', '')}")
                lines.append("")
        
        # 5. åˆ›æ–°å‡è®¾ç”Ÿæˆ
        innovations = result.get('innovations', {})
        hypotheses = innovations.get('hypotheses', []) if innovations else []
        if hypotheses:
            lines.append("## ğŸ’¡ åˆ›æ–°å‡è®¾\n")
            
            for idx, hyp in enumerate(hypotheses, 1):
                lines.append(f"### å‡è®¾ {idx}: {hyp.get('title', '')}\n")
                lines.append(f"**ID**: {hyp.get('id', '')}")
                lines.append(f"**ç½®ä¿¡åº¦**: {hyp.get('confidence', 0):.2%}\n")
                
                lines.append("#### æè¿°")
                lines.append(f"{hyp.get('description', '')}\n")
                
                lines.append("#### ç†è®ºä¾æ®")
                lines.append(f"{hyp.get('rationale', '')}\n")
                
                # å¯è¡Œæ€§
                feasibility = hyp.get('feasibility', {})
                lines.append("#### å¯è¡Œæ€§è¯„ä¼°")
                lines.append(f"- **æŠ€æœ¯å¯è¡Œæ€§**: {feasibility.get('technical', 'N/A')}")
                lines.append(f"- **èµ„æºå¯è¡Œæ€§**: {feasibility.get('resource', 'N/A')}")
                lines.append(f"- **æ—¶é—´å¯è¡Œæ€§**: {feasibility.get('time', 'N/A')}")
                lines.append("")
                
                # æ‰€éœ€èµ„æº
                resources = hyp.get('required_resources', {})
                if resources:
                    lines.append("#### æ‰€éœ€èµ„æº")
                    lines.append(f"- **èµ„é‡‘**: {resources.get('funding', 'N/A')}")
                    lines.append(f"- **å›¢é˜Ÿ**: {resources.get('team_size', 'N/A')}")
                    lines.append(f"- **å‘¨æœŸ**: {resources.get('duration', 'N/A')}")
                    lines.append("")
                
                # æ”¯æ’‘æ–‡çŒ®
                supporting = hyp.get('supporting_papers', [])
                if supporting:
                    lines.append("#### æ”¯æ’‘æ–‡çŒ®")
                    for paper in supporting[:3]:
                        lines.append(f"- {paper}")
                    lines.append("")
        
        # 6. åäº‹å®æ¨ç†
        counterfactuals = innovations.get('counterfactual_reasoning', []) if innovations else []
        if counterfactuals:
            lines.append("## ğŸ”® åäº‹å®æ¨ç†åˆ†æ\n")
            
            for cf_group in counterfactuals:
                hyp_id = cf_group.get('hypothesis_id', '')
                scenarios = cf_group.get('scenarios', [])
                
                if scenarios:
                    lines.append(f"### é’ˆå¯¹å‡è®¾ {hyp_id}\n")
                    
                    for idx, scenario in enumerate(scenarios, 1):
                        lines.append(f"#### åœºæ™¯ {idx}: {scenario.get('scenario', '')}\n")
                        
                        lines.append(f"**æ¡ä»¶å˜åŒ–**: {scenario.get('condition_change', '')}\n")
                        lines.append(f"**é¢„æœŸç»“æœ**: {scenario.get('expected_outcome', '')}\n")
                        lines.append(f"**æˆåŠŸæ¦‚ç‡**: {scenario.get('success_probability', 0):.2%}\n")
                        
                        risks = scenario.get('risks', [])
                        if risks:
                            lines.append("**æ½œåœ¨é£é™©**:")
                            for risk in risks:
                                lines.append(f"- {risk}")
                            lines.append("")
                        
                        adjustments = scenario.get('required_adjustments', [])
                        if adjustments:
                            lines.append("**æ‰€éœ€è°ƒæ•´**:")
                            for adj in adjustments:
                                lines.append(f"- {adj}")
                            lines.append("")
                        
                        lines.append(f"**æ—¶é—´å½±å“**: {scenario.get('impact_on_timeline', 'N/A')}")
                        lines.append(f"**èµ„æºå½±å“**: {scenario.get('impact_on_resources', 'N/A')}\n")
        
        # 7. è·¨åŸŸçŸ¥è¯†è¿ç§»
        transfers = innovations.get('cross_domain_transfers', []) if innovations else []
        if transfers:
            lines.append("## ğŸ”„ è·¨åŸŸçŸ¥è¯†è¿ç§»æ¨è\n")
            
            for idx, transfer in enumerate(transfers, 1):
                lines.append(f"### è¿ç§»æ–¹æ¡ˆ {idx}\n")
                lines.append(f"**æºé¢†åŸŸ**: {transfer.get('source_domain', '')}")
                lines.append(f"**ç›®æ ‡é¢†åŸŸ**: {transfer.get('target_domain', '')}")
                lines.append(f"**ç›¸ä¼¼åº¦**: {transfer.get('similarity_score', 0):.2%}")
                lines.append(f"**æˆåŠŸæ¦‚ç‡**: {transfer.get('success_probability', 0):.2%}\n")
                
                lines.append(f"**æºæ–¹æ³•**: {transfer.get('source_method', '')}")
                lines.append(f"**ç›®æ ‡åº”ç”¨**: {transfer.get('target_application', '')}\n")
                
                lines.append(f"**é¢„æœŸæ”¶ç›Š**: {transfer.get('expected_benefit', '')}\n")
                
                challenges = transfer.get('challenges', [])
                if challenges:
                    lines.append("**æŒ‘æˆ˜**:")
                    for challenge in challenges:
                        lines.append(f"- {challenge}")
                    lines.append("")
                
                steps = transfer.get('implementation_steps', [])
                if steps:
                    lines.append("**å®æ–½æ­¥éª¤**:")
                    for step in steps:
                        lines.append(f"{step}")
                    lines.append("")
        
        # é¡µè„š
        lines.append("\n---")
        lines.append("\n*æœ¬æŠ¥å‘Šç”± AI4S-Discovery è‡ªåŠ¨ç”Ÿæˆ*")
        
        return "\n".join(lines)


# åˆ›å»ºå…¨å±€æŠ¥å‘Šç”Ÿæˆå™¨å®ä¾‹
report_generator = ReportGenerator()
